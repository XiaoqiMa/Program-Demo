{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "796bfacd64b55"
   },
   "source": [
    "# Compute Notebook Data\n",
    "\n",
    "This notebook is devoted to calculating notebok statistics for further analysis. There are generally three types of stats we aim to calculate:\n",
    "1. Notebook metadata stored in the notebook itself (e.g., nbformat, kernel_lang)\n",
    "2. Descriptive information about cells, their type, and length\n",
    "3. Descriptive information about the content of cells (import statements, keywords, links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "ea3bb91a9f98a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "611afbab77e22"
   },
   "source": [
    "## 0. Load notebook, repo, and readme metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "comet_cell_id": "e97ca928a1607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1253620, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_id</th>\n",
       "      <th>html_url</th>\n",
       "      <th>max_filesize</th>\n",
       "      <th>min_filesize</th>\n",
       "      <th>name</th>\n",
       "      <th>owner_html_url</th>\n",
       "      <th>owner_id</th>\n",
       "      <th>owner_login</th>\n",
       "      <th>path</th>\n",
       "      <th>query_page</th>\n",
       "      <th>repo_description</th>\n",
       "      <th>repo_fork</th>\n",
       "      <th>repo_html_url</th>\n",
       "      <th>repo_id</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>repo_private</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://github.com/dalequark/emotivExperiment/...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>EmotivDataAnalysis.ipynb</td>\n",
       "      <td>https://github.com/dalequark</td>\n",
       "      <td>2328571</td>\n",
       "      <td>dalequark</td>\n",
       "      <td>ipynb/EmotivDataAnalysis.ipynb</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>https://github.com/dalequark/emotivExperiment</td>\n",
       "      <td>26093748</td>\n",
       "      <td>emotivExperiment</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://github.com/kevcisme/madelon_redux/blob...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Part_IV_Project_3-checkpoint_BASE_63907.ipynb</td>\n",
       "      <td>https://github.com/kevcisme</td>\n",
       "      <td>24496260</td>\n",
       "      <td>kevcisme</td>\n",
       "      <td>ipynb/.ipynb_checkpoints/Part_IV_Project_3-che...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>https://github.com/kevcisme/madelon_redux</td>\n",
       "      <td>95729593</td>\n",
       "      <td>madelon_redux</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://github.com/HaraldoFilho/DLND-Projects/...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>_.ipynb</td>\n",
       "      <td>https://github.com/HaraldoFilho</td>\n",
       "      <td>15271881</td>\n",
       "      <td>HaraldoFilho</td>\n",
       "      <td>_.ipynb</td>\n",
       "      <td>1</td>\n",
       "      <td>Index for the projects of the Udacity's \"Deep ...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://github.com/HaraldoFilho/DLND-Projects</td>\n",
       "      <td>88182909</td>\n",
       "      <td>DLND-Projects</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://github.com/mhjensen/CPMLS/blob/4a5b37e...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>csexmas2015.ipynb</td>\n",
       "      <td>https://github.com/mhjensen</td>\n",
       "      <td>2732953</td>\n",
       "      <td>mhjensen</td>\n",
       "      <td>doc/pub/CSETalks/csexmas2015/ipynb/csexmas2015...</td>\n",
       "      <td>1</td>\n",
       "      <td>Master program in Computational Science. The l...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://github.com/mhjensen/CPMLS</td>\n",
       "      <td>35169104</td>\n",
       "      <td>CPMLS</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://github.com/freqn/atom_configuration/bl...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>jupyter.ipynb</td>\n",
       "      <td>https://github.com/freqn</td>\n",
       "      <td>3611075</td>\n",
       "      <td>freqn</td>\n",
       "      <td>packages/file-icons/examples/jupyter.ipynb</td>\n",
       "      <td>1</td>\n",
       "      <td>Atom Config</td>\n",
       "      <td>False</td>\n",
       "      <td>https://github.com/freqn/atom_configuration</td>\n",
       "      <td>57460377</td>\n",
       "      <td>atom_configuration</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nb_id                                           html_url  max_filesize  \\\n",
       "0      0  https://github.com/dalequark/emotivExperiment/...            10   \n",
       "1      1  https://github.com/kevcisme/madelon_redux/blob...            10   \n",
       "2      2  https://github.com/HaraldoFilho/DLND-Projects/...            10   \n",
       "3      3  https://github.com/mhjensen/CPMLS/blob/4a5b37e...            10   \n",
       "4      4  https://github.com/freqn/atom_configuration/bl...            10   \n",
       "\n",
       "   min_filesize                                           name  \\\n",
       "0             0                       EmotivDataAnalysis.ipynb   \n",
       "1             0  Part_IV_Project_3-checkpoint_BASE_63907.ipynb   \n",
       "2             0                                        _.ipynb   \n",
       "3             0                              csexmas2015.ipynb   \n",
       "4             0                                  jupyter.ipynb   \n",
       "\n",
       "                    owner_html_url  owner_id   owner_login  \\\n",
       "0     https://github.com/dalequark   2328571     dalequark   \n",
       "1      https://github.com/kevcisme  24496260      kevcisme   \n",
       "2  https://github.com/HaraldoFilho  15271881  HaraldoFilho   \n",
       "3      https://github.com/mhjensen   2732953      mhjensen   \n",
       "4         https://github.com/freqn   3611075         freqn   \n",
       "\n",
       "                                                path  query_page  \\\n",
       "0                     ipynb/EmotivDataAnalysis.ipynb           1   \n",
       "1  ipynb/.ipynb_checkpoints/Part_IV_Project_3-che...           1   \n",
       "2                                            _.ipynb           1   \n",
       "3  doc/pub/CSETalks/csexmas2015/ipynb/csexmas2015...           1   \n",
       "4         packages/file-icons/examples/jupyter.ipynb           1   \n",
       "\n",
       "                                    repo_description  repo_fork  \\\n",
       "0                                                NaN      False   \n",
       "1                                                NaN      False   \n",
       "2  Index for the projects of the Udacity's \"Deep ...      False   \n",
       "3  Master program in Computational Science. The l...      False   \n",
       "4                                        Atom Config      False   \n",
       "\n",
       "                                   repo_html_url   repo_id  \\\n",
       "0  https://github.com/dalequark/emotivExperiment  26093748   \n",
       "1      https://github.com/kevcisme/madelon_redux  95729593   \n",
       "2  https://github.com/HaraldoFilho/DLND-Projects  88182909   \n",
       "3              https://github.com/mhjensen/CPMLS  35169104   \n",
       "4    https://github.com/freqn/atom_configuration  57460377   \n",
       "\n",
       "            repo_name  repo_private  \n",
       "0    emotivExperiment         False  \n",
       "1       madelon_redux         False  \n",
       "2       DLND-Projects         False  \n",
       "3               CPMLS         False  \n",
       "4  atom_configuration         False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notebook metadata\n",
    "df_nb = pd.read_csv('../data/csv/nb_metadata.csv')\n",
    "df_nb.rename(columns = {'Unnamed: 0':'nb_id'}, inplace = True)\n",
    "print(df_nb.shape)\n",
    "df_nb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "comet_cell_id": "7e3ca888c16d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193026, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>description</th>\n",
       "      <th>fork</th>\n",
       "      <th>forks_count</th>\n",
       "      <th>has_downloads</th>\n",
       "      <th>has_issues</th>\n",
       "      <th>has_pages</th>\n",
       "      <th>has_wiki</th>\n",
       "      <th>html_url</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>owner_id</th>\n",
       "      <th>owner_login</th>\n",
       "      <th>owner_type</th>\n",
       "      <th>private</th>\n",
       "      <th>pushed_at</th>\n",
       "      <th>size</th>\n",
       "      <th>stargazers_count</th>\n",
       "      <th>subscribers_count</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>watchers_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-03-01T23:35:48Z</td>\n",
       "      <td>Pysolar is a collection of Python libraries fo...</td>\n",
       "      <td>False</td>\n",
       "      <td>59</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>https://github.com/pingswept/pysolar</td>\n",
       "      <td>2058</td>\n",
       "      <td>...</td>\n",
       "      <td>1875</td>\n",
       "      <td>pingswept</td>\n",
       "      <td>User</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-05-29T13:34:12Z</td>\n",
       "      <td>4400</td>\n",
       "      <td>114</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-07-10T09:46:44Z</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-10-22T10:30:25Z</td>\n",
       "      <td>My uni homework</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>https://github.com/ELLIOTTCABLE/Homework</td>\n",
       "      <td>66233</td>\n",
       "      <td>...</td>\n",
       "      <td>200</td>\n",
       "      <td>ELLIOTTCABLE</td>\n",
       "      <td>User</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-10-05T10:48:54Z</td>\n",
       "      <td>634</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-05-08T15:22:05Z</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-09T21:05:22Z</td>\n",
       "      <td>Incubator for useful bioinformatics code, prim...</td>\n",
       "      <td>False</td>\n",
       "      <td>172</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>https://github.com/chapmanb/bcbb</td>\n",
       "      <td>87831</td>\n",
       "      <td>...</td>\n",
       "      <td>39391</td>\n",
       "      <td>chapmanb</td>\n",
       "      <td>User</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-07-23T10:26:58Z</td>\n",
       "      <td>67640</td>\n",
       "      <td>368</td>\n",
       "      <td>54</td>\n",
       "      <td>2017-07-25T13:10:17Z</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-02-01T23:43:19Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>https://github.com/certik/chess</td>\n",
       "      <td>119491</td>\n",
       "      <td>...</td>\n",
       "      <td>20568</td>\n",
       "      <td>certik</td>\n",
       "      <td>User</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-03-20T22:53:21Z</td>\n",
       "      <td>3006</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-05-09T00:40:15Z</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-02-02T22:26:08Z</td>\n",
       "      <td>Generic Disease Modelling System</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>https://github.com/aflaxman/gbd</td>\n",
       "      <td>120233</td>\n",
       "      <td>...</td>\n",
       "      <td>51236</td>\n",
       "      <td>aflaxman</td>\n",
       "      <td>User</td>\n",
       "      <td>False</td>\n",
       "      <td>2013-02-27T22:06:57Z</td>\n",
       "      <td>69051</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-08-30T23:29:41Z</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             created_at                                        description  \\\n",
       "0  2008-03-01T23:35:48Z  Pysolar is a collection of Python libraries fo...   \n",
       "1  2008-10-22T10:30:25Z                                    My uni homework   \n",
       "2  2008-12-09T21:05:22Z  Incubator for useful bioinformatics code, prim...   \n",
       "3  2009-02-01T23:43:19Z                                                NaN   \n",
       "4  2009-02-02T22:26:08Z                   Generic Disease Modelling System   \n",
       "\n",
       "    fork  forks_count  has_downloads  has_issues  has_pages  has_wiki  \\\n",
       "0  False           59           True        True       True     False   \n",
       "1  False            0           True        True      False      True   \n",
       "2  False          172           True        True       True     False   \n",
       "3  False            2           True        True      False      True   \n",
       "4  False            5           True        True      False      True   \n",
       "\n",
       "                                   html_url      id       ...       owner_id  \\\n",
       "0      https://github.com/pingswept/pysolar    2058       ...           1875   \n",
       "1  https://github.com/ELLIOTTCABLE/Homework   66233       ...            200   \n",
       "2          https://github.com/chapmanb/bcbb   87831       ...          39391   \n",
       "3           https://github.com/certik/chess  119491       ...          20568   \n",
       "4           https://github.com/aflaxman/gbd  120233       ...          51236   \n",
       "\n",
       "    owner_login  owner_type  private             pushed_at   size  \\\n",
       "0     pingswept        User    False  2017-05-29T13:34:12Z   4400   \n",
       "1  ELLIOTTCABLE        User    False  2016-10-05T10:48:54Z    634   \n",
       "2      chapmanb        User    False  2017-07-23T10:26:58Z  67640   \n",
       "3        certik        User    False  2016-03-20T22:53:21Z   3006   \n",
       "4      aflaxman        User    False  2013-02-27T22:06:57Z  69051   \n",
       "\n",
       "  stargazers_count  subscribers_count            updated_at  watchers_count  \n",
       "0              114                 24  2017-07-10T09:46:44Z             114  \n",
       "1                4                  3  2016-05-08T15:22:05Z               4  \n",
       "2              368                 54  2017-07-25T13:10:17Z             368  \n",
       "3                4                  4  2016-05-09T00:40:15Z               4  \n",
       "4               11                  3  2016-08-30T23:29:41Z              11  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repository metadata\n",
    "df_repo = pd.read_csv('../data/csv/repo_metadata.csv')\n",
    "del df_repo['Unnamed: 0']\n",
    "print(df_repo.shape)\n",
    "df_repo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "comet_cell_id": "89aa236be7fbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142449, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>html_url</th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>repo_id</th>\n",
       "      <th>size</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IyMgUHlzb2xhciAjIwoKWyFbQnVpbGQgU3RhdHVzXShodH...</td>\n",
       "      <td>https://github.com/pingswept/pysolar/blob/mast...</td>\n",
       "      <td>README.markdown</td>\n",
       "      <td>README.markdown</td>\n",
       "      <td>2058</td>\n",
       "      <td>3226</td>\n",
       "      <td>file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SG9tZXdvcmsKPT09PT09PT0KV2hhdCB0aGUgdGl0bGUgc2...</td>\n",
       "      <td>https://github.com/ELLIOTTCABLE/Homework/blob/...</td>\n",
       "      <td>README.markdown</td>\n",
       "      <td>README.markdown</td>\n",
       "      <td>66233</td>\n",
       "      <td>441</td>\n",
       "      <td>file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q29sbGVjdGlvbiBvZiB1c2VmdWwgY29kZSByZWxhdGVkIH...</td>\n",
       "      <td>https://github.com/chapmanb/bcbb/blob/master/R...</td>\n",
       "      <td>README.md</td>\n",
       "      <td>README.md</td>\n",
       "      <td>87831</td>\n",
       "      <td>1171</td>\n",
       "      <td>file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SW50cm9kdWN0aW9uDQo9PT09PT09PT09PT0NCg0KVGhpcy...</td>\n",
       "      <td>https://github.com/aflaxman/gbd/blob/master/RE...</td>\n",
       "      <td>README.rst</td>\n",
       "      <td>README.rst</td>\n",
       "      <td>120233</td>\n",
       "      <td>690</td>\n",
       "      <td>file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q0FQTyBOb3RlczoKUGFzdGVkIGZyb20gUEFQRVIgd2lraS...</td>\n",
       "      <td>https://github.com/HERA-Team/capo/blob/master/...</td>\n",
       "      <td>README</td>\n",
       "      <td>README</td>\n",
       "      <td>151115</td>\n",
       "      <td>1086</td>\n",
       "      <td>file</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  IyMgUHlzb2xhciAjIwoKWyFbQnVpbGQgU3RhdHVzXShodH...   \n",
       "1  SG9tZXdvcmsKPT09PT09PT0KV2hhdCB0aGUgdGl0bGUgc2...   \n",
       "2  Q29sbGVjdGlvbiBvZiB1c2VmdWwgY29kZSByZWxhdGVkIH...   \n",
       "3  SW50cm9kdWN0aW9uDQo9PT09PT09PT09PT0NCg0KVGhpcy...   \n",
       "4  Q0FQTyBOb3RlczoKUGFzdGVkIGZyb20gUEFQRVIgd2lraS...   \n",
       "\n",
       "                                            html_url             name  \\\n",
       "0  https://github.com/pingswept/pysolar/blob/mast...  README.markdown   \n",
       "1  https://github.com/ELLIOTTCABLE/Homework/blob/...  README.markdown   \n",
       "2  https://github.com/chapmanb/bcbb/blob/master/R...        README.md   \n",
       "3  https://github.com/aflaxman/gbd/blob/master/RE...       README.rst   \n",
       "4  https://github.com/HERA-Team/capo/blob/master/...           README   \n",
       "\n",
       "              path  repo_id  size  type  \n",
       "0  README.markdown     2058  3226  file  \n",
       "1  README.markdown    66233   441  file  \n",
       "2        README.md    87831  1171  file  \n",
       "3       README.rst   120233   690  file  \n",
       "4           README   151115  1086  file  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Readme metadtata\n",
    "df_readme = pd.read_csv('../data/csv/repo_readme.csv')\n",
    "del df_readme['Unnamed: 0']\n",
    "print(df_readme.shape)\n",
    "df_readme.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "578ca6efdf55e"
   },
   "source": [
    "## 1. Scrape Additional nb data from nb file\n",
    "\n",
    "We currently only have the metadata provided from Github's API. Now we can look at the nb files themselves and get the metadata from within the notebook (nbformat, kernel, langauge) and compute stats about each notebook (type and num of cell, and so on).\n",
    "\n",
    "For now let's test this metadata extraction with a subset of 1000 nbs. And if that works we can then apply the extraction code to all notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "comet_cell_id": "a69a6fa6a2f1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 23)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nb_sample = df_nb.sample(1000)\n",
    "df_nb_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "3d82bfb90475f"
   },
   "outputs": [],
   "source": [
    "def write_to_log(msg):\n",
    "    f = '../logs/nb_parse_log.txt'\n",
    "    log_file = open(f, \"a\")\n",
    "    log_file.write(msg + \"\\n\")\n",
    "    \n",
    "def get_nb_metadata(df):\n",
    "    # create blank columns for the data\n",
    "    df[\"nbformat\"] = None\n",
    "    df[\"nbformat_minor\"] = None\n",
    "    df[\"kernel_lang\"] = None\n",
    "    df[\"kernel_name\"] = None\n",
    "    df[\"lang_name\"] = None\n",
    "    df[\"lang_version\"] = None\n",
    "    df['num_cells'] = None\n",
    "    \n",
    "    # track time to process files\n",
    "    count = 0    \n",
    "    time1 = time.time()\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        # track time to process files\n",
    "        count += 1\n",
    "        if count % 10000 == 0:\n",
    "            print('%s rows in %s seconds' % (count, time.time() - time1))\n",
    "\n",
    "        f = '../data/notebooks/nb_%s.ipynb' % row['nb_id']\n",
    "        with open(f) as data_file:\n",
    "            date_string = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            try:\n",
    "                data = json.load(data_file)\n",
    "            except:\n",
    "                # track files we could not open\n",
    "                msg = '%s: had trouble loading %s' % (date_string, row['nb_id'])\n",
    "                write_to_log(msg)\n",
    "                continue\n",
    "\n",
    "            if isinstance(data, dict): \n",
    "                keys = data.keys()\n",
    "            else:\n",
    "                keys = []\n",
    "\n",
    "            # get nb top level metadata\n",
    "            if 'nbformat' in keys:\n",
    "                df.set_value(index, 'nbformat', data['nbformat'])\n",
    "            if 'nbformat_minor' in keys:\n",
    "                df.set_value(index, 'nbformat_minor', data['nbformat_minor'])\n",
    "            \n",
    "            # get information about the number of cells\n",
    "            if 'cells' in keys:\n",
    "                df.set_value(index, 'num_cells', len(data['cells']))\n",
    "            elif 'worksheets' in keys:\n",
    "                num_cells = 0\n",
    "                for w in data['worksheets']:\n",
    "                    num_cells += len(w['cells'])\n",
    "                df.set_value(index, 'num_cells', num_cells)\n",
    "\n",
    "            # get info from the metadata dictionary\n",
    "            if 'metadata' in keys:\n",
    "                metadata_keys = data['metadata'].keys()\n",
    "\n",
    "                if 'kernelspec' in metadata_keys:\n",
    "                    kernel_keys = data['metadata']['kernelspec'].keys()\n",
    "                    if 'language' in kernel_keys:\n",
    "                        df.set_value(index, 'kernel_lang', data['metadata']['kernelspec']['language'])\n",
    "                    if 'display_name' in kernel_keys:\n",
    "                        df.set_value(index, 'kernel_name', data['metadata']['kernelspec']['display_name'])\n",
    "\n",
    "                if 'language_info' in metadata_keys:\n",
    "                    lang_keys = data['metadata']['language_info'].keys()\n",
    "                    if 'name' in lang_keys:\n",
    "                        df.set_value(index, 'lang_name', data['metadata']['language_info']['name'])\n",
    "                    if 'version' in lang_keys:\n",
    "                        df.set_value(index, 'lang_version', data['metadata']['language_info']['version'])\n",
    "\n",
    "                elif 'language' in metadata_keys:\n",
    "                    df.set_value(index, 'lang_name', data['metadata']['language'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "1a3bd1aa75e93"
   },
   "source": [
    "We eventually got the code to work on the 1000 sample notebooks, so now we will apply it to the whole dataset. Here, as elsewhere I track how long the extraction is taking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "comet_cell_id": "8d58343c49acd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 rows in 66.51938724517822 seconds\n",
      "20000 rows in 106.40936398506165 seconds\n",
      "30000 rows in 233.25157499313354 seconds\n",
      "40000 rows in 280.3122229576111 seconds\n",
      "50000 rows in 327.68263602256775 seconds\n",
      "60000 rows in 431.2840702533722 seconds\n",
      "70000 rows in 475.36883091926575 seconds\n",
      "80000 rows in 515.8759350776672 seconds\n",
      "90000 rows in 693.012088060379 seconds\n",
      "100000 rows in 741.2404401302338 seconds\n",
      "110000 rows in 783.0808730125427 seconds\n",
      "120000 rows in 824.5476369857788 seconds\n",
      "130000 rows in 869.077358007431 seconds\n",
      "140000 rows in 912.9306890964508 seconds\n",
      "150000 rows in 1070.3463661670685 seconds\n",
      "160000 rows in 1116.3673310279846 seconds\n",
      "170000 rows in 1156.7598099708557 seconds\n",
      "180000 rows in 1214.2917590141296 seconds\n",
      "190000 rows in 1258.8786220550537 seconds\n",
      "200000 rows in 1502.3247511386871 seconds\n",
      "210000 rows in 1548.7590849399567 seconds\n",
      "220000 rows in 1600.6675288677216 seconds\n",
      "230000 rows in 1653.0572032928467 seconds\n",
      "240000 rows in 1697.7411050796509 seconds\n",
      "250000 rows in 1835.706012248993 seconds\n",
      "260000 rows in 1892.5084700584412 seconds\n",
      "270000 rows in 1933.4557070732117 seconds\n",
      "280000 rows in 1983.8532071113586 seconds\n",
      "290000 rows in 2174.783956050873 seconds\n",
      "300000 rows in 2234.5782430171967 seconds\n",
      "310000 rows in 2275.3528990745544 seconds\n",
      "320000 rows in 2328.4060010910034 seconds\n",
      "330000 rows in 2387.4722402095795 seconds\n",
      "340000 rows in 2442.408091068268 seconds\n",
      "350000 rows in 2503.2458879947662 seconds\n",
      "360000 rows in 2567.564782142639 seconds\n",
      "370000 rows in 2748.6947009563446 seconds\n",
      "380000 rows in 2801.930546283722 seconds\n",
      "390000 rows in 2850.74449300766 seconds\n",
      "400000 rows in 2901.893846988678 seconds\n",
      "410000 rows in 2956.573361158371 seconds\n",
      "420000 rows in 3003.7337939739227 seconds\n",
      "430000 rows in 3050.242136001587 seconds\n",
      "440000 rows in 3194.3949689865112 seconds\n",
      "450000 rows in 3254.4618752002716 seconds\n",
      "460000 rows in 3304.8099892139435 seconds\n",
      "470000 rows in 3351.0085501670837 seconds\n",
      "480000 rows in 3400.2568740844727 seconds\n",
      "490000 rows in 3441.078835964203 seconds\n",
      "500000 rows in 3651.9031410217285 seconds\n",
      "510000 rows in 3693.9233021736145 seconds\n",
      "520000 rows in 3733.7367820739746 seconds\n",
      "530000 rows in 3793.5553121566772 seconds\n",
      "540000 rows in 3833.317270040512 seconds\n",
      "550000 rows in 3873.0267610549927 seconds\n",
      "560000 rows in 3907.6155490875244 seconds\n",
      "570000 rows in 3955.958858013153 seconds\n",
      "580000 rows in 3991.978350162506 seconds\n",
      "590000 rows in 4041.62154006958 seconds\n",
      "600000 rows in 4310.946955919266 seconds\n",
      "610000 rows in 4335.539240121841 seconds\n",
      "620000 rows in 4380.614920139313 seconds\n",
      "630000 rows in 4432.52081990242 seconds\n",
      "640000 rows in 4455.505779981613 seconds\n",
      "650000 rows in 4502.157449007034 seconds\n",
      "660000 rows in 4552.059603214264 seconds\n",
      "670000 rows in 4605.167228221893 seconds\n",
      "680000 rows in 4630.899739027023 seconds\n",
      "690000 rows in 4683.643748044968 seconds\n",
      "700000 rows in 4735.40375494957 seconds\n",
      "710000 rows in 4788.427510023117 seconds\n",
      "720000 rows in 4810.745115041733 seconds\n",
      "730000 rows in 4858.03587603569 seconds\n",
      "740000 rows in 4905.722660064697 seconds\n",
      "750000 rows in 4956.163677215576 seconds\n",
      "760000 rows in 5010.162832021713 seconds\n",
      "770000 rows in 5259.806282043457 seconds\n",
      "780000 rows in 5316.929243087769 seconds\n",
      "790000 rows in 5347.277568101883 seconds\n",
      "800000 rows in 5418.266438245773 seconds\n",
      "810000 rows in 5447.914005041122 seconds\n",
      "820000 rows in 5512.987914085388 seconds\n",
      "830000 rows in 5539.692368030548 seconds\n",
      "840000 rows in 5611.29296708107 seconds\n",
      "850000 rows in 5638.138297080994 seconds\n",
      "860000 rows in 5717.632857084274 seconds\n",
      "870000 rows in 5749.576069116592 seconds\n",
      "880000 rows in 5822.975028038025 seconds\n",
      "890000 rows in 5883.301744222641 seconds\n",
      "900000 rows in 6128.2082259655 seconds\n",
      "910000 rows in 6184.426604986191 seconds\n",
      "920000 rows in 6236.118540048599 seconds\n",
      "930000 rows in 6305.886580944061 seconds\n",
      "940000 rows in 6361.605379104614 seconds\n",
      "950000 rows in 6386.6756999492645 seconds\n",
      "960000 rows in 6441.970118045807 seconds\n",
      "970000 rows in 6488.184308052063 seconds\n",
      "980000 rows in 6551.72793006897 seconds\n",
      "990000 rows in 6578.622267246246 seconds\n",
      "1000000 rows in 6652.515459060669 seconds\n",
      "1010000 rows in 6681.048869132996 seconds\n",
      "1020000 rows in 6708.902536153793 seconds\n",
      "1030000 rows in 6784.63082408905 seconds\n",
      "1040000 rows in 6806.503717184067 seconds\n",
      "1050000 rows in 6837.135677099228 seconds\n",
      "1060000 rows in 6909.671313047409 seconds\n",
      "1070000 rows in 6945.858078956604 seconds\n",
      "1080000 rows in 7226.769331216812 seconds\n",
      "1090000 rows in 7252.184328079224 seconds\n",
      "1100000 rows in 7278.56477689743 seconds\n",
      "1110000 rows in 7349.7533621788025 seconds\n",
      "1120000 rows in 7376.728235960007 seconds\n",
      "1130000 rows in 7489.170187950134 seconds\n",
      "1140000 rows in 7512.867295026779 seconds\n",
      "1150000 rows in 7548.082280874252 seconds\n",
      "1160000 rows in 7575.657500267029 seconds\n",
      "1170000 rows in 7688.570248842239 seconds\n",
      "1180000 rows in 7714.914883136749 seconds\n",
      "1190000 rows in 7747.349491119385 seconds\n",
      "1200000 rows in 7778.587624073029 seconds\n",
      "1210000 rows in 7899.128128051758 seconds\n",
      "1220000 rows in 7929.718556165695 seconds\n",
      "1230000 rows in 7953.37375998497 seconds\n",
      "1240000 rows in 7980.648865938187 seconds\n",
      "1250000 rows in 8090.051955938339 seconds\n"
     ]
    }
   ],
   "source": [
    "# get metadata and save updated dataframe to a csv file\n",
    "get_nb_metadata(df_nb)\n",
    "df_nb.to_csv('../data/csv/nb_metadata_w_nb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "08c73cdf5d50d"
   },
   "source": [
    "## 2. Get Data about Cell Types\n",
    "\n",
    "I want to track data on each cell. I think the best way to do this is to have a dataframe with a separate row for each cell. I think I want to track the following data. Some of the difficulty in writing this extraction code will be handling nbformat 3.0 that use a different format to store notebook data.\n",
    "\n",
    "1. nb_id\n",
    "2. workbook_index\n",
    "2. cell_index\n",
    "3. cell_type\n",
    "3. num_words (raw, markdown and headings)\n",
    "4. lines of code (code cells)\n",
    "5. num_execute_result\n",
    "6. execute_result_keys\n",
    "7. num_error\n",
    "8. error_names\n",
    "9. error_values\n",
    "10. num_stream\n",
    "11. num_display_data\n",
    "12. display_data_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "e3344d2be2458"
   },
   "outputs": [],
   "source": [
    "def write_to_log(msg):\n",
    "    f = '../logs/cell_parse_log.txt'\n",
    "    log_file = open(f, \"a\")\n",
    "    log_file.write(msg + \"\\n\")\n",
    "    #log_file.close()   \n",
    "    \n",
    "def get_all_cell_data(df, tracking_trigger = 10000):\n",
    "    \n",
    "    all_cells = []      \n",
    "    count = 0    \n",
    "    time1 = time.time()\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        # track progress through notebooks\n",
    "        count += 1\n",
    "        if count % tracking_trigger == 0:\n",
    "            print('%s nbs in %s seconds' % (count, time.time() - time1))\n",
    "\n",
    "        f = '../data/notebooks/nb_%s.ipynb' % row['nb_id']\n",
    "        with open(f) as nb_file:\n",
    "            date_string = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            try:\n",
    "                data = json.load(nb_file)\n",
    "            except:\n",
    "                msg = '%s: had trouble loading nb %s' % (date_string, row['nb_id'])\n",
    "                write_to_log(msg)\n",
    "                continue\n",
    "\n",
    "            if isinstance(data, dict): \n",
    "                keys = data.keys()\n",
    "            else:\n",
    "                keys = []\n",
    "\n",
    "            # get data for each cell, v 4.0\n",
    "            if 'cells' in keys:\n",
    "                for i, c in enumerate(data['cells']):\n",
    "                    cell_data = get_cell_data(c, i, row['nb_id'])\n",
    "                    all_cells.append(cell_data)\n",
    "            \n",
    "            # get data for each cell, v 3.0\n",
    "            elif 'worksheets' in keys:\n",
    "                for j, w in enumerate(data['worksheets']):\n",
    "                    \n",
    "                    if isinstance(w, dict): \n",
    "                        worksheet_keys = w.keys()\n",
    "                    else:\n",
    "                        keys = []\n",
    "                    \n",
    "                    if 'cells' in worksheet_keys:\n",
    "                        for k, c in enumerate(w['cells']):\n",
    "                            cell_data = get_cell_data(c, k, row['nb_id'], j)\n",
    "                            all_cells.append(cell_data)\n",
    "                \n",
    "    return all_cells\n",
    "    \n",
    "def get_cell_data(cell, index, nb_id, worksheet_index = None):\n",
    "    nbformat_3_mimes = ['text', 'latex', 'png', 'jpeg', 'svg', 'html', 'javascript', 'json', 'pdf', 'metadata']\n",
    "    \n",
    "    if isinstance(cell, dict): \n",
    "        cell_keys = cell.keys()\n",
    "    else:\n",
    "        cell_keys = [] \n",
    "    \n",
    "    if 'cell_type' in cell_keys:\n",
    "        cell_type = cell['cell_type']\n",
    "    else:\n",
    "        cell_type = None\n",
    "    \n",
    "    \n",
    "    if cell_type in ['raw','markdown','heading']:\n",
    "        num_words = 0\n",
    "        if 'source' in cell_keys:\n",
    "            if isinstance(cell['source'], list):\n",
    "                for l in cell['source']:\n",
    "                    words = len(l.split())\n",
    "                    num_words += words\n",
    "            elif isinstance(cell['source'], str):\n",
    "                num_words += len(cell['source'].split())\n",
    "            else:\n",
    "                num_words = None\n",
    "    else:\n",
    "        num_words = None\n",
    "    \n",
    "    if cell_type == 'code':\n",
    "        lines_of_code = 0\n",
    "        if 'source' in cell_keys:\n",
    "            if isinstance(cell['source'], list):\n",
    "                lines_of_code = len(cell['source'])\n",
    "            elif isinstance(cell['source'], str):\n",
    "                lines_of_code = len(cell['source'].splitlines())\n",
    "            else:\n",
    "                lines_of_code = None\n",
    "            \n",
    "        elif 'input' in cell_keys:\n",
    "            if isinstance(cell['input'], list):\n",
    "                lines_of_code = len(cell['input'])\n",
    "            elif isinstance(cell['input'], str):\n",
    "                lines_of_code = len(cell['input'].splitlines())\n",
    "            else:\n",
    "                lines_of_code = None\n",
    "    else:\n",
    "        lines_of_code = None\n",
    "    \n",
    "    \n",
    "    # inilize output counts\n",
    "    num_execute_result = 0\n",
    "    num_error = 0\n",
    "    num_stream = 0\n",
    "    num_display_data = 0\n",
    "    \n",
    "    execute_result_keys = []\n",
    "    error_names = []\n",
    "    error_values = []\n",
    "    display_data_keys = []\n",
    "        \n",
    "    if 'outputs' in cell_keys:\n",
    "        for o in cell['outputs']:\n",
    "\n",
    "            if isinstance(o, dict):\n",
    "                output_keys = o.keys()\n",
    "            else:\n",
    "                output_keys = []\n",
    "\n",
    "            if 'output_type' in output_keys:\n",
    "                if o['output_type'] in ['execute_result','pyout']:\n",
    "                    num_execute_result += 1\n",
    "                    if 'data' in output_keys:\n",
    "                        if isinstance(o['data'], dict):\n",
    "                            data_keys = o['data'].keys()\n",
    "                            for k in data_keys:\n",
    "                                execute_result_keys.append(k)\n",
    "                    else:\n",
    "                        for k in output_keys:\n",
    "                            if k in nbformat_3_mimes:\n",
    "                                execute_result_keys.append(k)\n",
    "\n",
    "                elif o['output_type'] in ['error','pyerr']:\n",
    "                    num_error += 1\n",
    "                    if 'ename' in output_keys:\n",
    "                        error_names.append(o['ename'])\n",
    "                    if 'evalue' in output_keys:\n",
    "                        error_values.append(o['evalue'])\n",
    "\n",
    "                elif o['output_type'] == 'stream':\n",
    "                    num_stream += 1\n",
    "\n",
    "                elif o['output_type'] == 'display_data':\n",
    "                    num_display_data += 1\n",
    "                    if 'data' in output_keys:\n",
    "                        if isinstance(o['data'], dict):\n",
    "                            data_keys = o['data'].keys()\n",
    "                            for k in data_keys:\n",
    "                                display_data_keys.append(k)\n",
    "                    else:\n",
    "                        for k in output_keys:\n",
    "                            if k in nbformat_3_mimes:\n",
    "                                display_data_keys.append(k)\n",
    "\n",
    "    return [nb_id, worksheet_index, index, cell_type, num_words, lines_of_code, \n",
    "            num_execute_result, execute_result_keys, num_error, error_names, \n",
    "            error_values, num_stream, num_display_data, display_data_keys]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "d4b51d85dcbd1"
   },
   "source": [
    "As is best practice, let's use a subset of the data to test our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "comet_cell_id": "5d4fd3dd2049a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 nbs in 1.8204798698425293 seconds\n",
      "200 nbs in 3.8096261024475098 seconds\n",
      "300 nbs in 5.4645349979400635 seconds\n",
      "400 nbs in 7.0867249965667725 seconds\n",
      "500 nbs in 8.622582912445068 seconds\n",
      "600 nbs in 9.964746952056885 seconds\n",
      "700 nbs in 11.574764013290405 seconds\n",
      "800 nbs in 13.0364248752594 seconds\n",
      "900 nbs in 14.345754146575928 seconds\n",
      "1000 nbs in 15.574757099151611 seconds\n"
     ]
    }
   ],
   "source": [
    "sample_cell_data = get_all_cell_data(df_nb_sample, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "22e272ef8c1d4"
   },
   "source": [
    "And let's see how the celld ata looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "comet_cell_id": "f5b43f44707c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21560, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_id</th>\n",
       "      <th>workbook_index</th>\n",
       "      <th>cell_index</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>num_words</th>\n",
       "      <th>lines_of_code</th>\n",
       "      <th>num_execute_result</th>\n",
       "      <th>execute_result_keys</th>\n",
       "      <th>num_error</th>\n",
       "      <th>error_names</th>\n",
       "      <th>error_values</th>\n",
       "      <th>num_stream</th>\n",
       "      <th>num_display_data</th>\n",
       "      <th>display_data_keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>950229</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>markdown</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>950229</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>950229</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>markdown</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>950229</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[text/plain]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>950229</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>950229</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>markdown</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>950229</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>950229</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>950229</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>950229</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>950229</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>950229</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[text/plain]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>950229</td>\n",
       "      <td>None</td>\n",
       "      <td>12</td>\n",
       "      <td>code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[text/plain]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>371672</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>371672</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>371672</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>371672</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>371672</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>371672</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>371672</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     nb_id workbook_index  cell_index cell_type  num_words  lines_of_code  \\\n",
       "0   950229           None           0  markdown        5.0            NaN   \n",
       "1   950229           None           1      code        NaN            8.0   \n",
       "2   950229           None           2  markdown        7.0            NaN   \n",
       "3   950229           None           3      code        NaN            2.0   \n",
       "4   950229           None           4      code        NaN           14.0   \n",
       "5   950229           None           5  markdown       11.0            NaN   \n",
       "6   950229           None           6      code        NaN            6.0   \n",
       "7   950229           None           7      code        NaN            1.0   \n",
       "8   950229           None           8      code        NaN            1.0   \n",
       "9   950229           None           9      code        NaN            1.0   \n",
       "10  950229           None          10      code        NaN            1.0   \n",
       "11  950229           None          11      code        NaN            1.0   \n",
       "12  950229           None          12      code        NaN            1.0   \n",
       "13  371672           None           0      code        NaN            1.0   \n",
       "14  371672           None           1      code        NaN            1.0   \n",
       "15  371672           None           2      code        NaN            1.0   \n",
       "16  371672           None           3      code        NaN            1.0   \n",
       "17  371672           None           4      code        NaN            1.0   \n",
       "18  371672           None           5      code        NaN            4.0   \n",
       "19  371672           None           6      code        NaN            0.0   \n",
       "\n",
       "    num_execute_result execute_result_keys  num_error error_names  \\\n",
       "0                    0                  []          0          []   \n",
       "1                    0                  []          0          []   \n",
       "2                    0                  []          0          []   \n",
       "3                    1        [text/plain]          0          []   \n",
       "4                    0                  []          0          []   \n",
       "5                    0                  []          0          []   \n",
       "6                    0                  []          0          []   \n",
       "7                    0                  []          0          []   \n",
       "8                    0                  []          0          []   \n",
       "9                    0                  []          0          []   \n",
       "10                   0                  []          0          []   \n",
       "11                   1        [text/plain]          0          []   \n",
       "12                   1        [text/plain]          0          []   \n",
       "13                   0                  []          0          []   \n",
       "14                   0                  []          0          []   \n",
       "15                   0                  []          0          []   \n",
       "16                   0                  []          0          []   \n",
       "17                   0                  []          0          []   \n",
       "18                   0                  []          0          []   \n",
       "19                   0                  []          0          []   \n",
       "\n",
       "   error_values  num_stream  num_display_data display_data_keys  \n",
       "0            []           0                 0                []  \n",
       "1            []           0                 0                []  \n",
       "2            []           0                 0                []  \n",
       "3            []           0                 0                []  \n",
       "4            []           1                 0                []  \n",
       "5            []           0                 0                []  \n",
       "6            []           1                 0                []  \n",
       "7            []           1                 0                []  \n",
       "8            []           0                 0                []  \n",
       "9            []           1                 0                []  \n",
       "10           []           1                 0                []  \n",
       "11           []           0                 0                []  \n",
       "12           []           0                 0                []  \n",
       "13           []           0                 0                []  \n",
       "14           []           0                 0                []  \n",
       "15           []           0                 0                []  \n",
       "16           []           0                 0                []  \n",
       "17           []           0                 0                []  \n",
       "18           []           0                 0                []  \n",
       "19           []           0                 0                []  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cell = pd.DataFrame(sample_cell_data)\n",
    "print(df_cell.shape)\n",
    "df_cell.columns = ['nb_id','workbook_index','cell_index','cell_type','num_words','lines_of_code',\n",
    "                   'num_execute_result','execute_result_keys','num_error','error_names','error_values',\n",
    "                   'num_stream','num_display_data','display_data_keys']\n",
    "df_cell.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "759ccdb170279"
   },
   "outputs": [],
   "source": [
    "df_cell.to_csv('../data/csv/cell_metadata_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "e26a700003268"
   },
   "source": [
    "Alright, that computing of cell data seemed to work on 1000 notebooks, now for the 1.25 million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "comet_cell_id": "f38fdab6ce532"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 nbs in 51.6393301486969 seconds\n",
      "20000 nbs in 96.67775797843933 seconds\n",
      "30000 nbs in 211.67645001411438 seconds\n",
      "40000 nbs in 261.78705406188965 seconds\n",
      "50000 nbs in 318.10353207588196 seconds\n",
      "60000 nbs in 427.5553991794586 seconds\n",
      "70000 nbs in 474.3860511779785 seconds\n",
      "80000 nbs in 516.8671221733093 seconds\n",
      "90000 nbs in 701.8724331855774 seconds\n",
      "100000 nbs in 750.3447201251984 seconds\n",
      "110000 nbs in 798.1056818962097 seconds\n",
      "120000 nbs in 839.1192629337311 seconds\n",
      "130000 nbs in 884.4429590702057 seconds\n",
      "140000 nbs in 940.4327092170715 seconds\n",
      "150000 nbs in 1103.9290418624878 seconds\n",
      "160000 nbs in 1145.1924579143524 seconds\n",
      "170000 nbs in 1196.874055147171 seconds\n",
      "180000 nbs in 1256.7895259857178 seconds\n",
      "190000 nbs in 1299.6017332077026 seconds\n",
      "200000 nbs in 1560.0286478996277 seconds\n",
      "210000 nbs in 1612.138699054718 seconds\n",
      "220000 nbs in 1665.2173948287964 seconds\n",
      "230000 nbs in 1720.3766241073608 seconds\n",
      "240000 nbs in 1770.952070236206 seconds\n",
      "250000 nbs in 1930.45654296875 seconds\n",
      "260000 nbs in 1987.774353981018 seconds\n",
      "270000 nbs in 2027.9114711284637 seconds\n",
      "280000 nbs in 2078.8822560310364 seconds\n",
      "290000 nbs in 2276.956682920456 seconds\n",
      "300000 nbs in 2351.0197520256042 seconds\n",
      "310000 nbs in 2393.186933994293 seconds\n",
      "320000 nbs in 2448.6896300315857 seconds\n",
      "330000 nbs in 2509.922529935837 seconds\n",
      "340000 nbs in 2565.8419001102448 seconds\n",
      "350000 nbs in 2637.621735095978 seconds\n",
      "360000 nbs in 2702.35706114769 seconds\n",
      "370000 nbs in 2893.5100989341736 seconds\n",
      "380000 nbs in 2949.485123157501 seconds\n",
      "390000 nbs in 2999.673696041107 seconds\n",
      "400000 nbs in 3052.380494117737 seconds\n",
      "410000 nbs in 3108.901848077774 seconds\n",
      "420000 nbs in 3158.426920890808 seconds\n",
      "430000 nbs in 3221.064709186554 seconds\n",
      "440000 nbs in 3371.9319269657135 seconds\n",
      "450000 nbs in 3431.9365770816803 seconds\n",
      "460000 nbs in 3483.800318956375 seconds\n",
      "470000 nbs in 3530.7681698799133 seconds\n",
      "480000 nbs in 3581.5767500400543 seconds\n",
      "490000 nbs in 3624.4228279590607 seconds\n",
      "500000 nbs in 3845.2809710502625 seconds\n",
      "510000 nbs in 3899.7848150730133 seconds\n",
      "520000 nbs in 3940.861020088196 seconds\n",
      "530000 nbs in 4003.2564401626587 seconds\n",
      "540000 nbs in 4074.2703778743744 seconds\n",
      "550000 nbs in 4116.3468542099 seconds\n",
      "560000 nbs in 4153.606160163879 seconds\n",
      "570000 nbs in 4205.875293016434 seconds\n",
      "580000 nbs in 4244.9524269104 seconds\n",
      "590000 nbs in 4297.513583183289 seconds\n",
      "600000 nbs in 4575.0151998996735 seconds\n",
      "610000 nbs in 4614.270046949387 seconds\n",
      "620000 nbs in 4660.768817186356 seconds\n",
      "630000 nbs in 4714.199879169464 seconds\n",
      "640000 nbs in 4739.609806060791 seconds\n",
      "650000 nbs in 4786.9290680885315 seconds\n",
      "660000 nbs in 4839.917432069778 seconds\n",
      "670000 nbs in 4896.847893953323 seconds\n",
      "680000 nbs in 4927.452115058899 seconds\n",
      "690000 nbs in 4982.439652204514 seconds\n",
      "700000 nbs in 5035.993694067001 seconds\n",
      "710000 nbs in 5106.412026166916 seconds\n",
      "720000 nbs in 5130.562244176865 seconds\n",
      "730000 nbs in 5181.469801902771 seconds\n",
      "740000 nbs in 5244.049917936325 seconds\n",
      "750000 nbs in 5296.62189412117 seconds\n",
      "760000 nbs in 5360.540850162506 seconds\n",
      "770000 nbs in 5625.811524152756 seconds\n",
      "780000 nbs in 5682.210716962814 seconds\n",
      "790000 nbs in 5713.412777900696 seconds\n",
      "800000 nbs in 5789.236466169357 seconds\n",
      "810000 nbs in 5821.360795021057 seconds\n",
      "820000 nbs in 5889.517549991608 seconds\n",
      "830000 nbs in 5917.890964984894 seconds\n",
      "840000 nbs in 5991.628731250763 seconds\n",
      "850000 nbs in 6021.727158069611 seconds\n",
      "860000 nbs in 6105.157811880112 seconds\n",
      "870000 nbs in 6139.025550127029 seconds\n",
      "880000 nbs in 6235.722273111343 seconds\n",
      "890000 nbs in 6310.319628953934 seconds\n",
      "900000 nbs in 6587.409070014954 seconds\n",
      "910000 nbs in 6655.34548997879 seconds\n",
      "920000 nbs in 6722.819885969162 seconds\n",
      "930000 nbs in 6801.26966714859 seconds\n",
      "940000 nbs in 6877.122502088547 seconds\n",
      "950000 nbs in 6906.878249883652 seconds\n",
      "960000 nbs in 6968.085087060928 seconds\n",
      "970000 nbs in 7018.878655910492 seconds\n",
      "980000 nbs in 7086.946969032288 seconds\n",
      "990000 nbs in 7118.514975070953 seconds\n",
      "1000000 nbs in 7203.4614980220795 seconds\n",
      "1010000 nbs in 7235.919112920761 seconds\n",
      "1020000 nbs in 7267.747694015503 seconds\n",
      "1030000 nbs in 7353.743661165237 seconds\n",
      "1040000 nbs in 7379.702022075653 seconds\n",
      "1050000 nbs in 7415.367626905441 seconds\n",
      "1060000 nbs in 7496.421581983566 seconds\n",
      "1070000 nbs in 7649.714163064957 seconds\n",
      "1080000 nbs in 7951.34380698204 seconds\n",
      "1090000 nbs in 7979.472465991974 seconds\n",
      "1100000 nbs in 8009.786525011063 seconds\n",
      "1110000 nbs in 8087.559676885605 seconds\n",
      "1120000 nbs in 8120.092629909515 seconds\n",
      "1130000 nbs in 8243.72106385231 seconds\n",
      "1140000 nbs in 8275.043359994888 seconds\n",
      "1150000 nbs in 8314.80474805832 seconds\n",
      "1160000 nbs in 8346.331575155258 seconds\n",
      "1170000 nbs in 8466.870192050934 seconds\n",
      "1180000 nbs in 8498.828675985336 seconds\n",
      "1190000 nbs in 8527.106701135635 seconds\n",
      "1200000 nbs in 8555.67893910408 seconds\n",
      "1210000 nbs in 8673.32939696312 seconds\n",
      "1220000 nbs in 8708.86400103569 seconds\n",
      "1230000 nbs in 8739.852780103683 seconds\n",
      "1240000 nbs in 8772.164583921432 seconds\n",
      "1250000 nbs in 8888.139310121536 seconds\n",
      "(29997824, 14)\n"
     ]
    }
   ],
   "source": [
    "all_cell_data = get_all_cell_data(df_nb, 10000)\n",
    "\n",
    "df_cell = pd.DataFrame(all_cell_data)\n",
    "print(df_cell.shape)\n",
    "df_cell.columns = ['nb_id','workbook_index','cell_index','cell_type','num_words','lines_of_code',\n",
    "                   'num_execute_result','execute_result_keys','num_error','error_names','error_values',\n",
    "                   'num_stream','num_display_data','display_data_keys']\n",
    "\n",
    "df_cell.to_csv('../data/csv/cell_metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "c03a0b1fbe14c"
   },
   "source": [
    "## Scrape nbformat 2.0 and 3.0 cells\n",
    "\n",
    "Coming back from a break, it appears I did not check my code closely last time as I have a large number of files that did not get parsed. These are mainly the nbformat 2.0 and 3.0 files that store cells in a worksheet.\n",
    "\n",
    "First up, I need a list of those files that did not make it into the list, igoring the ones that did not parse since these are simply due to malformatted json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "comet_cell_id": "3212b4cb32adc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12054"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_cell_data = []\n",
    "\n",
    "with open('../logs/cell_parse_log.txt', 'r') as f:\n",
    "    for l in f:\n",
    "        missing_cell_data.append(int(l.split(' ')[6]))\n",
    "\n",
    "missing_cell_data = set(missing_cell_data)\n",
    "missing_cell_data = np.array(list(missing_cell_data))\n",
    "len(missing_cell_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "9cecd9e5a6fc8"
   },
   "outputs": [],
   "source": [
    "df_cell = pd.read_csv('../data/csv/cell_metadata.csv')\n",
    "nbs_with_cell_data = df_cell.nb_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "comet_cell_id": "6b9b86a3368fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1079894"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbs_not_reparse = np.unique(np.append(missing_cell_data, nbs_with_cell_data))\n",
    "len(nbs_not_reparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "comet_cell_id": "de675a3e5a8ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173726, 23)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nbs_to_reparse = df_nb[~df_nb.nb_id.isin(nbs_not_reparse)]\n",
    "df_nbs_to_reparse.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "a52e0c952e78c"
   },
   "source": [
    "Okay, so we have ~173k notebooks that were not parsed and that are not a part of our known problem notebooks (i.e. ones with malformatted json that we could not get metadata from in step 1)\n",
    "\n",
    "Let's test the revised code to make sure it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "comet_cell_id": "8ed4785aa7f23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 nbs in 1.71806001663208 seconds\n",
      "200 nbs in 3.44852614402771 seconds\n",
      "300 nbs in 5.113385915756226 seconds\n",
      "400 nbs in 6.739964008331299 seconds\n",
      "500 nbs in 8.426445007324219 seconds\n",
      "600 nbs in 10.00645899772644 seconds\n",
      "700 nbs in 11.894474029541016 seconds\n",
      "800 nbs in 13.5018949508667 seconds\n",
      "900 nbs in 15.192470073699951 seconds\n",
      "1000 nbs in 16.959682941436768 seconds\n"
     ]
    }
   ],
   "source": [
    "df_nbs_to_reparse_sample = df_nbs_to_reparse.sample(1000)\n",
    "\n",
    "sample_reparse = get_all_cell_data(df_nbs_to_reparse_sample, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "24009f61a4a5f"
   },
   "outputs": [],
   "source": [
    "df_sample_reparse = pd.DataFrame(sample_reparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "4620901f63f19"
   },
   "outputs": [],
   "source": [
    "df_sample_reparse.shape\n",
    "df_sample_reparse.columns = ['nb_id','workbook_index','cell_index','cell_type','num_words','lines_of_code',\n",
    "                   'num_execute_result','execute_result_keys','num_error','error_names','error_values',\n",
    "                   'num_stream','num_display_data','display_data_keys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "comet_cell_id": "63c7ff93ea7cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "987"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sample_reparse['nb_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "e817e5a34106a"
   },
   "source": [
    "Yep, of the 1000 notebooks we tried to get data on, 13 didn't work. That is likely to more JSON malformatting issues. Okay, that sample worked, so now for all the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "comet_cell_id": "93bea9ff4053"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 nbs in 96.36146402359009 seconds\n",
      "20000 nbs in 194.91301703453064 seconds\n",
      "30000 nbs in 448.3327031135559 seconds\n",
      "40000 nbs in 548.8574161529541 seconds\n",
      "50000 nbs in 681.528135061264 seconds\n",
      "60000 nbs in 799.5319352149963 seconds\n",
      "70000 nbs in 904.6161372661591 seconds\n",
      "80000 nbs in 1007.1710021495819 seconds\n",
      "90000 nbs in 1117.6736481189728 seconds\n",
      "100000 nbs in 1200.3324780464172 seconds\n",
      "110000 nbs in 1310.8296191692352 seconds\n",
      "120000 nbs in 1388.7029349803925 seconds\n",
      "130000 nbs in 1501.5205039978027 seconds\n",
      "140000 nbs in 1571.8860640525818 seconds\n",
      "150000 nbs in 1660.7107701301575 seconds\n",
      "160000 nbs in 1728.6355922222137 seconds\n",
      "170000 nbs in 1798.524698972702 seconds\n",
      "(4693111, 14)\n"
     ]
    }
   ],
   "source": [
    "reparse_cell_data = get_all_cell_data(df_nbs_to_reparse, 10000)\n",
    "\n",
    "df_cell_reparse = pd.DataFrame(reparse_cell_data)\n",
    "print(df_cell_reparse.shape)\n",
    "df_cell_reparse.columns = ['nb_id','workbook_index','cell_index','cell_type','num_words','lines_of_code',\n",
    "                   'num_execute_result','execute_result_keys','num_error','error_names','error_values',\n",
    "                   'num_stream','num_display_data','display_data_keys']\n",
    "\n",
    "df_cell_reparse.to_csv('../data/csv/cell_metadata_v2-3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "b5b8af054304c"
   },
   "outputs": [],
   "source": [
    "reparsed_nbs = df_cell_reparse.nb_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "comet_cell_id": "3da54039f3dcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1239355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(reparsed_nbs) + len(nbs_with_cell_data))\n",
    "len(np.intersect1d(reparsed_nbs, nbs_not_reparse, assume_unique=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "666d1e462d2c4"
   },
   "source": [
    "Between our first pass (which mainly got data from nbformat 4.0 notebooks) and this pass (which included 2.0 and 3.0 notebooks) we have 1.24 million notebooks, none of which overlap between the two lists. Now we can merge the two lists and save the updated csv file about cell data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "comet_cell_id": "c2c60b46001e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1239355"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cell_all = pd.concat([df_cell_reparse, df_cell])\n",
    "len(df_cell_all.nb_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "577e9cf65f145"
   },
   "outputs": [],
   "source": [
    "df_cell_all.to_csv('../data/csv/cell_metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "59d0e60002217"
   },
   "source": [
    "## 3. Data about Cell Content\n",
    "\n",
    "This will be the more complex parsing of data files. The main things we may want to get for now are imports, headers, and links. \n",
    "\n",
    "For the imports, I will need to watch for:\n",
    "1. Python (import, from)\n",
    "2. R (library, require)\n",
    "3. Julia (using, import, importall)\n",
    "\n",
    "I won't look at other languages as they all had less than 0.1 % of the full sample. \n",
    "\n",
    "For headers we can look for # in the markdown as well as the header cells in notebooks written in nbformat 2.0 - 3.0.\n",
    "\n",
    "For links we may just use a regular expression. However, will this capture relative links? For that we may need to do another regular expression and check if the value returned looks like a url. If not, we may assume it is a relative link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "comet_cell_id": "6a8bded8d5e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34690935, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>cell_index</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>display_data_keys</th>\n",
       "      <th>error_names</th>\n",
       "      <th>error_values</th>\n",
       "      <th>execute_result_keys</th>\n",
       "      <th>lines_of_code</th>\n",
       "      <th>nb_id</th>\n",
       "      <th>num_display_data</th>\n",
       "      <th>num_error</th>\n",
       "      <th>num_execute_result</th>\n",
       "      <th>num_stream</th>\n",
       "      <th>num_words</th>\n",
       "      <th>workbook_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>heading</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>markdown</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>code</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>code</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>markdown</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  cell_index cell_type display_data_keys  \\\n",
       "0           0           NaN           0   heading                []   \n",
       "1           1           NaN           1  markdown                []   \n",
       "2           2           NaN           2      code                []   \n",
       "3           3           NaN           3      code                []   \n",
       "4           4           NaN           4  markdown                []   \n",
       "\n",
       "  error_names error_values execute_result_keys  lines_of_code  nb_id  \\\n",
       "0          []           []                  []            NaN    609   \n",
       "1          []           []                  []            NaN    609   \n",
       "2          []           []                  []            1.0    609   \n",
       "3          []           []                  []            1.0    609   \n",
       "4          []           []                  []            NaN    609   \n",
       "\n",
       "   num_display_data  num_error  num_execute_result  num_stream  num_words  \\\n",
       "0                 0          0                   0           0        4.0   \n",
       "1                 0          0                   0           0        5.0   \n",
       "2                 0          0                   0           1        NaN   \n",
       "3                 0          0                   0           0        NaN   \n",
       "4                 0          0                   0           0       13.0   \n",
       "\n",
       "   workbook_index  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell metadata\n",
    "df_cell = pd.read_csv('../data/csv/cell_metadata.csv')\n",
    "#df_nb.rename(columns = {'Unnamed: 0':'nb_id'}, inplace = True)\n",
    "print(df_cell.shape)\n",
    "df_cell.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "6e766fdbefeb8"
   },
   "outputs": [],
   "source": [
    "df_nb_sample = df_nb.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "4d2095d044dad"
   },
   "outputs": [],
   "source": [
    "def write_to_log(msg, log_name):\n",
    "    f = '../logs/%s.txt' % log_name\n",
    "    log_file = open(f, \"a\")\n",
    "    log_file.write(msg + \"\\n\")\n",
    "\n",
    "def get_cell_content_data(df, tracking_trigger = 10000):\n",
    "    \n",
    "    all_cells = []      \n",
    "    count = 0    \n",
    "    time1 = time.time()\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        # track progress through notebooks\n",
    "        count += 1\n",
    "        if count % tracking_trigger == 0:\n",
    "            print('%s nbs in %s seconds' % (count, time.time() - time1))\n",
    "\n",
    "        f = '../data/notebooks/nb_%s.ipynb' % row['nb_id']\n",
    "        with open(f) as nb_file:\n",
    "            date_string = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            try:\n",
    "                data = json.load(nb_file)\n",
    "            except:\n",
    "                msg = '%s: had trouble loading nb %s' % (date_string, row['nb_id'])\n",
    "                write_to_log(msg, 'cell_parse_content')\n",
    "                continue\n",
    "\n",
    "            if isinstance(data, dict): \n",
    "                keys = data.keys()\n",
    "            else:\n",
    "                keys = []\n",
    "                \n",
    "            # get the language\n",
    "            nb_language = None\n",
    "            if 'metadata' in keys:\n",
    "                if isinstance(data, dict):\n",
    "                    metadata_keys = data['metadata'].keys()\n",
    "                else:\n",
    "                    metadata_keys = []\n",
    "            else:\n",
    "                metadata_keys = []\n",
    "            if 'language_info' in metadata_keys:\n",
    "                if isinstance(data['metadata']['language_info'], dict):\n",
    "                    lang_keys = data['metadata']['language_info'].keys()\n",
    "                else:\n",
    "                    lang_keys = None\n",
    "                if 'name' in lang_keys:\n",
    "                    nb_language = data['metadata']['language_info']['name']\n",
    "            elif 'language' in metadata_keys:\n",
    "                nb_language = data['metadata']['language']\n",
    "\n",
    "            # get data for each cell, nbformat v 4.x\n",
    "            if 'cells' in keys:\n",
    "                for i, c in enumerate(data['cells']):\n",
    "                    cell_data = get_cell_data(c, i, row['nb_id'], nb_language)\n",
    "                    all_cells.append(cell_data)\n",
    "            \n",
    "            # get data for each cell, nbformat v 2.x / 3.x\n",
    "            elif 'worksheets' in keys:\n",
    "                for j, w in enumerate(data['worksheets']):\n",
    "                    if isinstance(w, dict): \n",
    "                        worksheet_keys = w.keys()\n",
    "                    else:\n",
    "                        keys = []\n",
    "                    if 'cells' in worksheet_keys:\n",
    "                        for k, c in enumerate(w['cells']):\n",
    "                            cell_data = get_cell_data(c, k, row['nb_id'], nb_language, j)\n",
    "                            all_cells.append(cell_data)\n",
    "                \n",
    "    return all_cells\n",
    "   \n",
    "\n",
    "def get_cell_data(cell, index, nb_id, nb_language, worksheet_index = None):\n",
    "\n",
    "    if isinstance(cell, dict): \n",
    "        cell_keys = cell.keys()\n",
    "    else:\n",
    "        cell_keys = [] \n",
    "    \n",
    "    # get the cell type\n",
    "    if 'cell_type' in cell_keys:\n",
    "        cell_type = cell['cell_type']\n",
    "    else:\n",
    "        cell_type = None\n",
    "    \n",
    "    headings = []\n",
    "    links = []\n",
    "    imports = []\n",
    "    \n",
    "   # get the imports for python, Julia, and R\n",
    "    if cell_type == 'code':\n",
    "        \n",
    "        lines_of_code = []\n",
    "        \n",
    "        if 'source' in cell_keys:\n",
    "            if isinstance(cell['source'], list):\n",
    "                lines_of_code = cell['source']\n",
    "            elif isinstance(cell['source'], str):\n",
    "                lines_of_code = cell['source'].splitlines()\n",
    "            \n",
    "        elif 'input' in cell_keys:\n",
    "            if isinstance(cell['input'], list):\n",
    "                lines_of_code = cell['input']\n",
    "            elif isinstance(cell['input'], str):\n",
    "                lines_of_code = cell['input'].splitlines()\n",
    "                \n",
    "        if nb_language == 'python':\n",
    "            import_words = ['import', 'from']\n",
    "        elif nb_language == 'R':\n",
    "            import_words = ['library', 'require']\n",
    "        elif nb_language in ['Julia', 'julia']:\n",
    "            import_words = ['import', 'importall', 'using']\n",
    "        else:\n",
    "            import_words = []\n",
    "            \n",
    "        # get imports\n",
    "        for l in lines_of_code:\n",
    "            words = [x for x in re.split('\\(|\\)|\\s*', l)if x]\n",
    "            if len(words) >1:\n",
    "                if words[0] in import_words:                    \n",
    "                    imports.append(words[1])\n",
    "    \n",
    "    \n",
    "    elif cell_type in ['heading', 'markdown']:\n",
    "        \n",
    "        \n",
    "        # get the lines of markdown\n",
    "        lines_of_markdown = []\n",
    "        if 'source' in cell_keys:\n",
    "            if isinstance(cell['source'], list):\n",
    "                lines_of_markdown = cell['source']\n",
    "            elif isinstance(cell['source'], str):\n",
    "                lines_of_markdown = cell['source'].splitlines()\n",
    "        \n",
    "        # track headings in heading cells\n",
    "        if 'level' in cell_keys:\n",
    "            if 'source' in cell_keys:\n",
    "                if len(lines_of_markdown) > 0:\n",
    "                    headings.append([cell['level'], cell['source']])\n",
    "        \n",
    "        for l in lines_of_markdown:\n",
    "            # get headings in markdown cells\n",
    "            words = [x for x in re.split('\\s*', l)if x]\n",
    "            if len(words) > 2:\n",
    "                if words[0] in ['#', '##', '###', '####', '#####', '######']:\n",
    "                    headings.append([len(words[0]), l.split(words[0])[1]])\n",
    "\n",
    "\n",
    "            # get links\n",
    "            urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', l)\n",
    "            all_links = re.findall('\\[([^]]+)]\\(\\s*(\\S*)\\)', l)\n",
    "            for al in all_links:\n",
    "                if al[:4] != 'http':\n",
    "                    urls.append(al)\n",
    "            for u in urls:\n",
    "                links.append(u)\n",
    "                \n",
    "    return [nb_id, nb_language, index, worksheet_index, len(imports), imports, len(headings), headings, len(links), links]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "comet_cell_id": "029d45e95d239"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/doug/anaconda/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 nbs in 89.49553108215332 seconds\n",
      "20000 nbs in 152.4832980632782 seconds\n",
      "30000 nbs in 299.51114320755005 seconds\n",
      "40000 nbs in 362.0098571777344 seconds\n",
      "50000 nbs in 423.6947419643402 seconds\n",
      "60000 nbs in 557.3618211746216 seconds\n",
      "70000 nbs in 615.9819240570068 seconds\n",
      "80000 nbs in 678.034924030304 seconds\n",
      "90000 nbs in 874.8168749809265 seconds\n",
      "100000 nbs in 948.9306139945984 seconds\n",
      "110000 nbs in 1002.5217590332031 seconds\n",
      "120000 nbs in 1071.4504733085632 seconds\n",
      "130000 nbs in 1131.0978531837463 seconds\n",
      "140000 nbs in 1190.4886672496796 seconds\n",
      "150000 nbs in 1372.1092112064362 seconds\n",
      "160000 nbs in 1427.0663442611694 seconds\n",
      "170000 nbs in 1477.3288660049438 seconds\n",
      "180000 nbs in 1568.324743270874 seconds\n",
      "190000 nbs in 1624.2207202911377 seconds\n",
      "200000 nbs in 1885.0916562080383 seconds\n",
      "210000 nbs in 1957.902288198471 seconds\n",
      "220000 nbs in 2029.415874004364 seconds\n",
      "230000 nbs in 2096.896448135376 seconds\n",
      "240000 nbs in 2161.0267741680145 seconds\n",
      "250000 nbs in 2315.6539692878723 seconds\n",
      "260000 nbs in 2401.120073080063 seconds\n",
      "270000 nbs in 2458.995297193527 seconds\n",
      "280000 nbs in 2527.1078341007233 seconds\n",
      "290000 nbs in 2738.9103581905365 seconds\n",
      "300000 nbs in 2822.855035305023 seconds\n",
      "310000 nbs in 2880.040239095688 seconds\n",
      "320000 nbs in 2949.8064420223236 seconds\n",
      "330000 nbs in 3028.3821601867676 seconds\n",
      "340000 nbs in 3099.8800671100616 seconds\n",
      "350000 nbs in 3178.4208550453186 seconds\n",
      "360000 nbs in 3277.925493001938 seconds\n",
      "370000 nbs in 3480.346081018448 seconds\n",
      "380000 nbs in 3550.7310383319855 seconds\n",
      "390000 nbs in 3615.697517156601 seconds\n",
      "400000 nbs in 3683.8861050605774 seconds\n",
      "410000 nbs in 3755.9084873199463 seconds\n",
      "420000 nbs in 3820.9868671894073 seconds\n",
      "430000 nbs in 3896.2320771217346 seconds\n",
      "440000 nbs in 4058.4396159648895 seconds\n",
      "450000 nbs in 4133.81902217865 seconds\n",
      "460000 nbs in 4201.71409201622 seconds\n",
      "470000 nbs in 4265.122828006744 seconds\n",
      "480000 nbs in 4330.264795303345 seconds\n",
      "490000 nbs in 4390.408399105072 seconds\n",
      "500000 nbs in 4624.54909324646 seconds\n",
      "510000 nbs in 4684.904812097549 seconds\n",
      "520000 nbs in 4757.32219004631 seconds\n",
      "530000 nbs in 4835.961404323578 seconds\n",
      "540000 nbs in 4893.565432071686 seconds\n",
      "550000 nbs in 4951.591486930847 seconds\n",
      "560000 nbs in 5003.232782125473 seconds\n",
      "570000 nbs in 5069.97869515419 seconds\n",
      "580000 nbs in 5123.319299221039 seconds\n",
      "590000 nbs in 5189.943873167038 seconds\n",
      "600000 nbs in 5483.97695016861 seconds\n",
      "610000 nbs in 5534.677032232285 seconds\n",
      "620000 nbs in 5597.261283159256 seconds\n",
      "630000 nbs in 5666.954096078873 seconds\n",
      "640000 nbs in 5708.101029157639 seconds\n",
      "650000 nbs in 5771.00864815712 seconds\n",
      "660000 nbs in 5838.338509082794 seconds\n",
      "670000 nbs in 5910.926416158676 seconds\n",
      "680000 nbs in 5955.282804012299 seconds\n",
      "690000 nbs in 6026.568785190582 seconds\n",
      "700000 nbs in 6096.557006120682 seconds\n",
      "710000 nbs in 6170.101118326187 seconds\n",
      "720000 nbs in 6210.21950006485 seconds\n",
      "730000 nbs in 6277.115337133408 seconds\n",
      "740000 nbs in 6357.969591140747 seconds\n",
      "750000 nbs in 6427.5450003147125 seconds\n",
      "760000 nbs in 6504.0871431827545 seconds\n",
      "770000 nbs in 6767.268722295761 seconds\n",
      "780000 nbs in 6839.226057052612 seconds\n",
      "790000 nbs in 6885.362501144409 seconds\n",
      "800000 nbs in 6977.608586072922 seconds\n",
      "810000 nbs in 7025.511955976486 seconds\n",
      "820000 nbs in 7112.281118154526 seconds\n",
      "830000 nbs in 7158.467273950577 seconds\n",
      "840000 nbs in 7251.231594085693 seconds\n",
      "850000 nbs in 7296.707373142242 seconds\n",
      "860000 nbs in 7397.272436141968 seconds\n",
      "870000 nbs in 7447.1029732227325 seconds\n",
      "880000 nbs in 7570.452437162399 seconds\n",
      "890000 nbs in 7651.285825014114 seconds\n",
      "900000 nbs in 7910.026871204376 seconds\n",
      "910000 nbs in 7993.787154197693 seconds\n",
      "920000 nbs in 8066.258733034134 seconds\n",
      "930000 nbs in 8154.621236085892 seconds\n",
      "940000 nbs in 8231.268998146057 seconds\n",
      "950000 nbs in 8273.746516942978 seconds\n",
      "960000 nbs in 8350.283723115921 seconds\n",
      "970000 nbs in 8417.181621074677 seconds\n",
      "980000 nbs in 8499.860312223434 seconds\n",
      "990000 nbs in 8542.692520141602 seconds\n",
      "1000000 nbs in 8636.812382221222 seconds\n",
      "1010000 nbs in 8682.914156198502 seconds\n",
      "1020000 nbs in 8730.774671077728 seconds\n",
      "1030000 nbs in 8827.545327186584 seconds\n",
      "1040000 nbs in 8867.72259092331 seconds\n",
      "1050000 nbs in 8919.919497013092 seconds\n",
      "1060000 nbs in 9097.381534337997 seconds\n",
      "1070000 nbs in 9155.295894145966 seconds\n",
      "1080000 nbs in 9449.366125106812 seconds\n",
      "1090000 nbs in 9491.391468048096 seconds\n",
      "1100000 nbs in 9535.768416166306 seconds\n",
      "1110000 nbs in 9628.49822306633 seconds\n",
      "1120000 nbs in 9675.507545232773 seconds\n",
      "1130000 nbs in 9809.264050245285 seconds\n",
      "1140000 nbs in 9855.036107063293 seconds\n",
      "1150000 nbs in 9910.070399999619 seconds\n",
      "1160000 nbs in 9954.865757226944 seconds\n",
      "1170000 nbs in 10090.632122278214 seconds\n",
      "1180000 nbs in 10137.578226327896 seconds\n",
      "1190000 nbs in 10178.726165056229 seconds\n",
      "1200000 nbs in 10221.098775148392 seconds\n",
      "1210000 nbs in 10355.26208114624 seconds\n",
      "1220000 nbs in 10404.235136985779 seconds\n",
      "1230000 nbs in 10446.897441148758 seconds\n",
      "1240000 nbs in 10492.04829621315 seconds\n",
      "1250000 nbs in 10619.784330129623 seconds\n"
     ]
    }
   ],
   "source": [
    "all_cell_content = get_cell_content_data(df_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "cb42e39629816"
   },
   "outputs": [],
   "source": [
    "df_cell_content = pd.DataFrame(all_cell_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "691506e612b65"
   },
   "outputs": [],
   "source": [
    "df_cell_content.columns = ['nb_id', 'nb_language', 'cell_index', 'workbook_index', \n",
    "                           'num_imports', 'imports', 'num_headers', 'headers',\n",
    "                           'num_links', 'links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "9520a847069cb"
   },
   "outputs": [],
   "source": [
    "df_cell_meta_content = df_cell.merge(df_cell_content, how = 'left', on = ['nb_id', 'cell_index', 'workbook_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "68159bbb87ef3"
   },
   "outputs": [],
   "source": [
    "del df_cell_meta_content['Unnamed: 0']\n",
    "del df_cell_meta_content['Unnamed: 0.1']\n",
    "del df_cell_meta_content['nb_language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "d34d1b6e95f5d"
   },
   "outputs": [],
   "source": [
    "df_cell_meta_content.to_csv('../data/csv/cell_metadata_content.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "7e646245550e9"
   },
   "source": [
    "And now to the analysis! I think"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "a5873679b2f6a"
   },
   "source": [
    "## 4.0 More Data about Cell (code) Content \n",
    "\n",
    "After doing some of the later analysis for this project, we decided that we want a little more data about each notebook. Namely the code contents with comments, use of functions, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "comet_cell_id": "9ca3dd999fd13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34690935\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cell_index</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>display_data_keys</th>\n",
       "      <th>error_names</th>\n",
       "      <th>error_values</th>\n",
       "      <th>execute_result_keys</th>\n",
       "      <th>lines_of_code</th>\n",
       "      <th>nb_id</th>\n",
       "      <th>num_display_data</th>\n",
       "      <th>...</th>\n",
       "      <th>num_execute_result</th>\n",
       "      <th>num_stream</th>\n",
       "      <th>num_words</th>\n",
       "      <th>workbook_index</th>\n",
       "      <th>num_imports</th>\n",
       "      <th>imports</th>\n",
       "      <th>num_headers</th>\n",
       "      <th>headers</th>\n",
       "      <th>num_links</th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>heading</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>[[1, ['NumPy and Matplotlib examples']]]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>markdown</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>code</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>code</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>markdown</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  cell_index cell_type display_data_keys error_names  \\\n",
       "0           0           0   heading                []          []   \n",
       "1           1           1  markdown                []          []   \n",
       "2           2           2      code                []          []   \n",
       "3           3           3      code                []          []   \n",
       "4           4           4  markdown                []          []   \n",
       "\n",
       "  error_values execute_result_keys  lines_of_code  nb_id  num_display_data  \\\n",
       "0           []                  []            NaN    609                 0   \n",
       "1           []                  []            NaN    609                 0   \n",
       "2           []                  []            1.0    609                 0   \n",
       "3           []                  []            1.0    609                 0   \n",
       "4           []                  []            NaN    609                 0   \n",
       "\n",
       "   ...    num_execute_result  num_stream  num_words  workbook_index  \\\n",
       "0  ...                     0           0        4.0             0.0   \n",
       "1  ...                     0           0        5.0             0.0   \n",
       "2  ...                     0           1        NaN             0.0   \n",
       "3  ...                     0           0        NaN             0.0   \n",
       "4  ...                     0           0       13.0             0.0   \n",
       "\n",
       "   num_imports  imports num_headers                                   headers  \\\n",
       "0            0       []           1  [[1, ['NumPy and Matplotlib examples']]]   \n",
       "1            0       []           0                                        []   \n",
       "2            0       []           0                                        []   \n",
       "3            0       []           0                                        []   \n",
       "4            0       []           0                                        []   \n",
       "\n",
       "  num_links  links  \n",
       "0         0     []  \n",
       "1         0     []  \n",
       "2         0     []  \n",
       "3         0     []  \n",
       "4         0     []  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load cell metadata\n",
    "df_cell = pd.read_csv('../data/csv/cell_metadata_content.csv')\n",
    "\n",
    "print(df_cell.shape[0])\n",
    "df_cell.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "6fb4a86dc9da7"
   },
   "outputs": [],
   "source": [
    "# get list of nbs to check\n",
    "nbs_w_cells = df_cell['nb_id'].unique()\n",
    "nbs_w_cells.shape[0]\n",
    "\n",
    "df_nbs_cells = df_nb[df_nb['nb_id'].isin(nbs_w_cells)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "eb735b845181d"
   },
   "outputs": [],
   "source": [
    "def write_to_log(msg, log_name):\n",
    "    f = '../logs/%s.txt' % log_name\n",
    "    log_file = open(f, \"a\")\n",
    "    log_file.write(msg + \"\\n\")\n",
    "\n",
    "def get_cell_code_metadata(df, tracking_trigger = 10000):\n",
    "    \n",
    "    all_cells = []      \n",
    "    count = 0    \n",
    "    time1 = time.time()\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        # track progress through notebooks\n",
    "        count += 1\n",
    "        if count % tracking_trigger == 0:\n",
    "            print('%s nbs in %s seconds' % (count, time.time() - time1))\n",
    "\n",
    "        f = '../data/notebooks/nb_%s.ipynb' % row['nb_id']\n",
    "        with open(f) as nb_file:\n",
    "            date_string = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            try:\n",
    "                data = json.load(nb_file)\n",
    "            except:\n",
    "                msg = '%s: had trouble loading nb %s' % (date_string, row['nb_id'])\n",
    "                write_to_log(msg, 'cell_parse_code_content')\n",
    "                continue\n",
    "\n",
    "            if isinstance(data, dict): \n",
    "                keys = data.keys()\n",
    "            else:\n",
    "                keys = []\n",
    "\n",
    "            # get the language\n",
    "            nb_language = None\n",
    "            if 'metadata' in keys:\n",
    "                if isinstance(data, dict):\n",
    "                    metadata_keys = data['metadata'].keys()\n",
    "                else:\n",
    "                    metadata_keys = []\n",
    "            else:\n",
    "                metadata_keys = []\n",
    "            if 'language_info' in metadata_keys:\n",
    "                if isinstance(data['metadata']['language_info'], dict):\n",
    "                    lang_keys = data['metadata']['language_info'].keys()\n",
    "                else:\n",
    "                    lang_keys = None\n",
    "                if 'name' in lang_keys:\n",
    "                    nb_language = data['metadata']['language_info']['name']\n",
    "            elif 'language' in metadata_keys:\n",
    "                nb_language = data['metadata']['language']\n",
    "                \n",
    "            # get data for each cell, nbformat v 4.x\n",
    "            if 'cells' in keys:\n",
    "                for i, c in enumerate(data['cells']):\n",
    "                    cell_data = get_cell_data(c, i, row['nb_id'], nb_language)\n",
    "                    all_cells.append(cell_data)\n",
    "            \n",
    "            # get data for each cell, nbformat v 2.x / 3.x\n",
    "            elif 'worksheets' in keys:\n",
    "                for j, w in enumerate(data['worksheets']):\n",
    "                    if isinstance(w, dict): \n",
    "                        worksheet_keys = w.keys()\n",
    "                    else:\n",
    "                        keys = []\n",
    "                    if 'cells' in worksheet_keys:\n",
    "                        for k, c in enumerate(w['cells']):\n",
    "                            cell_data = get_cell_data(c, k, row['nb_id'], nb_language, j)\n",
    "                            all_cells.append(cell_data)\n",
    "                \n",
    "    return all_cells\n",
    "\n",
    "def get_cell_data(cell, index, nb_id, nb_language, worksheet_index = None):\n",
    "\n",
    "    if isinstance(cell, dict): \n",
    "        cell_keys = cell.keys()\n",
    "    else:\n",
    "        cell_keys = [] \n",
    "    \n",
    "    # get the cell type\n",
    "    if 'cell_type' in cell_keys:\n",
    "        cell_type = cell['cell_type']\n",
    "    else:\n",
    "        cell_type = None\n",
    "    \n",
    "    functions = []\n",
    "    classes = []\n",
    "    comments = 0\n",
    "    comments_words = 0\n",
    "    in_multiline = False\n",
    "    \n",
    "   # get the imports for python, Julia, and R\n",
    "    if cell_type == 'code':\n",
    "        \n",
    "        # get lines of code\n",
    "        lines_of_code = []\n",
    "        if 'source' in cell_keys:\n",
    "            if isinstance(cell['source'], list):\n",
    "                lines_of_code = cell['source']\n",
    "            elif isinstance(cell['source'], str):\n",
    "                lines_of_code = cell['source'].splitlines()          \n",
    "        elif 'input' in cell_keys:\n",
    "            if isinstance(cell['input'], list):\n",
    "                lines_of_code = cell['input']\n",
    "            elif isinstance(cell['input'], str):\n",
    "                lines_of_code = cell['input'].splitlines()\n",
    "                \n",
    "        if nb_language == 'python':\n",
    "            for l in lines_of_code:\n",
    "                l = l.lstrip()\n",
    "                parts = l.split()\n",
    "                if len(parts) >= 2:                \n",
    "                    if l.startswith('def'):\n",
    "                        functions.append(parts[1].split('(')[0])\n",
    "                    elif l.startswith('class'):\n",
    "                        classes.append(parts[1].split('(')[0])\n",
    "                \n",
    "                if in_multiline:\n",
    "                    comments += 1\n",
    "                    comments_words += len(parts) - 1\n",
    "                \n",
    "                if l.startswith('\"\"\"'):\n",
    "                    if not in_multiline:\n",
    "                        comments += 1\n",
    "                        comments_words += len(parts) - 1\n",
    "                    in_multiline = not in_multiline\n",
    "                elif l.startswith(\"'''\"):\n",
    "                    if not in_multiline:\n",
    "                        comments += 1\n",
    "                        comments_words += len(parts) - 1\n",
    "                    in_multiline = not in_multiline\n",
    "                elif l.startswith('#'):\n",
    "                    comments += 1\n",
    "                    comments_words += len(parts) - 1\n",
    "                \n",
    "                \n",
    "    return [nb_id, nb_language, index, worksheet_index, len(functions), functions, len(classes), classes, comments, comments_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "comet_cell_id": "48c6868a779d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 nbs in 100.05687093734741 seconds\n",
      "20000 nbs in 154.06442880630493 seconds\n",
      "30000 nbs in 294.8419370651245 seconds\n",
      "40000 nbs in 347.7073030471802 seconds\n",
      "50000 nbs in 398.4782769680023 seconds\n",
      "60000 nbs in 515.4168570041656 seconds\n",
      "70000 nbs in 567.0472660064697 seconds\n",
      "80000 nbs in 612.7847809791565 seconds\n",
      "90000 nbs in 801.9396131038666 seconds\n",
      "100000 nbs in 848.1235349178314 seconds\n",
      "110000 nbs in 892.9966039657593 seconds\n",
      "120000 nbs in 945.7173871994019 seconds\n",
      "130000 nbs in 993.585531949997 seconds\n",
      "140000 nbs in 1093.6600029468536 seconds\n",
      "150000 nbs in 1260.6267700195312 seconds\n",
      "160000 nbs in 1302.7648758888245 seconds\n",
      "170000 nbs in 1355.7270030975342 seconds\n",
      "180000 nbs in 1408.9285321235657 seconds\n",
      "190000 nbs in 1456.095136165619 seconds\n",
      "200000 nbs in 1740.700397014618 seconds\n",
      "210000 nbs in 1788.9886770248413 seconds\n",
      "220000 nbs in 1834.3918809890747 seconds\n",
      "230000 nbs in 1896.7951159477234 seconds\n",
      "240000 nbs in 2057.247360944748 seconds\n",
      "250000 nbs in 2106.0779650211334 seconds\n",
      "260000 nbs in 2152.246078968048 seconds\n",
      "270000 nbs in 2206.2912809848785 seconds\n",
      "280000 nbs in 2254.130028963089 seconds\n",
      "290000 nbs in 2479.0287828445435 seconds\n",
      "300000 nbs in 2531.0812010765076 seconds\n",
      "310000 nbs in 2588.8242321014404 seconds\n",
      "320000 nbs in 2647.511307954788 seconds\n",
      "330000 nbs in 2706.8955109119415 seconds\n",
      "340000 nbs in 2773.3869099617004 seconds\n",
      "350000 nbs in 2842.2509319782257 seconds\n",
      "360000 nbs in 2997.502103805542 seconds\n",
      "370000 nbs in 3098.125368833542 seconds\n",
      "380000 nbs in 3148.3718729019165 seconds\n",
      "390000 nbs in 3204.7948009967804 seconds\n",
      "400000 nbs in 3286.6498777866364 seconds\n",
      "410000 nbs in 3345.1986269950867 seconds\n",
      "420000 nbs in 3398.3360211849213 seconds\n",
      "430000 nbs in 3555.1828439235687 seconds\n",
      "440000 nbs in 3608.5356090068817 seconds\n",
      "450000 nbs in 3671.6151189804077 seconds\n",
      "460000 nbs in 3725.097979068756 seconds\n",
      "470000 nbs in 3777.1283621788025 seconds\n",
      "480000 nbs in 3840.5709998607635 seconds\n",
      "490000 nbs in 4082.1678948402405 seconds\n",
      "500000 nbs in 4129.93713593483 seconds\n",
      "510000 nbs in 4175.103456020355 seconds\n",
      "520000 nbs in 4219.482928991318 seconds\n",
      "530000 nbs in 4281.33384513855 seconds\n",
      "540000 nbs in 4338.432178974152 seconds\n",
      "550000 nbs in 4379.153568029404 seconds\n",
      "560000 nbs in 4422.1597809791565 seconds\n",
      "570000 nbs in 4480.413324832916 seconds\n",
      "580000 nbs in 4537.954124927521 seconds\n",
      "590000 nbs in 4817.7510941028595 seconds\n",
      "600000 nbs in 4872.186132192612 seconds\n",
      "610000 nbs in 4925.693500041962 seconds\n",
      "620000 nbs in 4975.965913057327 seconds\n",
      "630000 nbs in 5008.963356018066 seconds\n",
      "640000 nbs in 5059.386079072952 seconds\n",
      "650000 nbs in 5117.238863945007 seconds\n",
      "660000 nbs in 5149.811950922012 seconds\n",
      "670000 nbs in 5209.338861942291 seconds\n",
      "680000 nbs in 5269.071102142334 seconds\n",
      "690000 nbs in 5329.698923110962 seconds\n",
      "700000 nbs in 5479.954108953476 seconds\n",
      "710000 nbs in 5510.27420091629 seconds\n",
      "720000 nbs in 5566.72989988327 seconds\n",
      "730000 nbs in 5623.944022893906 seconds\n",
      "740000 nbs in 5679.432374954224 seconds\n",
      "750000 nbs in 5741.943984985352 seconds\n",
      "760000 nbs in 6029.559533834457 seconds\n",
      "770000 nbs in 6093.947764158249 seconds\n",
      "780000 nbs in 6130.555321931839 seconds\n",
      "790000 nbs in 6214.15634393692 seconds\n",
      "800000 nbs in 6248.064544200897 seconds\n",
      "810000 nbs in 6326.576366901398 seconds\n",
      "820000 nbs in 6360.306365013123 seconds\n",
      "830000 nbs in 6446.538891077042 seconds\n",
      "840000 nbs in 6481.068948030472 seconds\n",
      "850000 nbs in 6578.694646835327 seconds\n",
      "860000 nbs in 6623.353782892227 seconds\n",
      "870000 nbs in 6705.65368103981 seconds\n",
      "880000 nbs in 6782.761058807373 seconds\n",
      "890000 nbs in 7055.4397621154785 seconds\n",
      "900000 nbs in 7122.607126951218 seconds\n",
      "910000 nbs in 7184.276203155518 seconds\n",
      "920000 nbs in 7264.689400911331 seconds\n",
      "930000 nbs in 7331.981328010559 seconds\n",
      "940000 nbs in 7367.204832792282 seconds\n",
      "950000 nbs in 7432.009999036789 seconds\n",
      "960000 nbs in 7528.224278926849 seconds\n",
      "970000 nbs in 7563.356205940247 seconds\n",
      "980000 nbs in 7596.99237704277 seconds\n",
      "990000 nbs in 7682.1303679943085 seconds\n",
      "1000000 nbs in 7721.432518959045 seconds\n",
      "1010000 nbs in 7753.44562292099 seconds\n",
      "1020000 nbs in 7841.942613840103 seconds\n",
      "1030000 nbs in 7877.1875150203705 seconds\n",
      "1040000 nbs in 7910.875934123993 seconds\n",
      "1050000 nbs in 7998.340309858322 seconds\n",
      "1060000 nbs in 8037.163022041321 seconds\n",
      "1070000 nbs in 8501.3209130764 seconds\n",
      "1080000 nbs in 8539.061439990997 seconds\n",
      "1090000 nbs in 8628.425950050354 seconds\n",
      "1100000 nbs in 8664.482695102692 seconds\n",
      "1110000 nbs in 8703.739027023315 seconds\n",
      "1120000 nbs in 8846.993490934372 seconds\n",
      "1130000 nbs in 8889.505599021912 seconds\n",
      "1140000 nbs in 8928.972382068634 seconds\n",
      "1150000 nbs in 8969.199517965317 seconds\n",
      "1160000 nbs in 9123.135452985764 seconds\n",
      "1170000 nbs in 9156.462376117706 seconds\n",
      "1180000 nbs in 9191.552442073822 seconds\n",
      "1190000 nbs in 9234.666141986847 seconds\n",
      "1200000 nbs in 9372.712015867233 seconds\n",
      "1210000 nbs in 9410.276489973068 seconds\n",
      "1220000 nbs in 9448.306105852127 seconds\n",
      "1230000 nbs in 9493.0521838665 seconds\n"
     ]
    }
   ],
   "source": [
    "cell_code_content = get_cell_code_metadata(df_nbs_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "819d5c49a2201"
   },
   "outputs": [],
   "source": [
    "df_code = pd.DataFrame(cell_code_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "comet_cell_id": "3a513f76c329f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_id</th>\n",
       "      <th>language</th>\n",
       "      <th>cell_index</th>\n",
       "      <th>workbook_index</th>\n",
       "      <th>num_functions</th>\n",
       "      <th>name_functions</th>\n",
       "      <th>num_classes</th>\n",
       "      <th>name_classes</th>\n",
       "      <th>num_comment_lines</th>\n",
       "      <th>num_comment_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>585</td>\n",
       "      <td>python</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>585</td>\n",
       "      <td>python</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>585</td>\n",
       "      <td>python</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>585</td>\n",
       "      <td>python</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>585</td>\n",
       "      <td>python</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>[wavwrite, stft, spectrogram, mel2freq, freq2m...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>141</td>\n",
       "      <td>858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nb_id language  cell_index  workbook_index  num_functions  \\\n",
       "0    585   python           0             NaN              0   \n",
       "1    585   python           1             NaN              0   \n",
       "2    585   python           2             NaN              0   \n",
       "3    585   python           3             NaN              0   \n",
       "4    585   python           4             NaN              7   \n",
       "\n",
       "                                      name_functions  num_classes  \\\n",
       "0                                                 []            0   \n",
       "1                                                 []            0   \n",
       "2                                                 []            0   \n",
       "3                                                 []            0   \n",
       "4  [wavwrite, stft, spectrogram, mel2freq, freq2m...            0   \n",
       "\n",
       "  name_classes  num_comment_lines  num_comment_words  \n",
       "0           []                  0                  0  \n",
       "1           []                  0                  0  \n",
       "2           []                  2                 38  \n",
       "3           []                  0                  0  \n",
       "4           []                141                858  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_code.columns = ['nb_id',\n",
    "                    'language',\n",
    "                    'cell_index',\n",
    "                    'workbook_index',\n",
    "                    'num_functions',\n",
    "                    'name_functions',\n",
    "                    'num_classes',\n",
    "                    'name_classes',\n",
    "                    'num_comment_lines',\n",
    "                    'num_comment_words']\n",
    "df_code.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "f1cf8aacfdb75"
   },
   "outputs": [],
   "source": [
    "df_code.to_csv('../data/csv/cell_metadata_code.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "e49770065446"
   },
   "source": [
    "And that's a wrap. Now we should have almost all the data we need to do our [core analysis of the notebooks](7_notebook_profiling.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "be7f527b4c264"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "comet_paths": [
   [
    "b47baa7f/7_profile_repo_metadata.ipynb",
    1500911449472
   ],
   [
    "b47baa7f/7_compute_nb_data.ipynb",
    1500938567916
   ],
   [
    "d1dd24ab/7_compute_nb_data.ipynb",
    1501096485356
   ],
   [
    "d1dd24ab/6_compute_nb_data.ipynb",
    1501176179258
   ]
  ],
  "comet_tracking": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
